{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TensorFlow事始め"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TensorFlowって何？\n",
    "\n",
    "- http://tensorflow.org/\n",
    "- [米Google、機械学習システム「TensorFlow」をOSSとして公開](http://itpro.nikkeibp.co.jp/atcl/news/15/111003663/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TensorFlowのチュートリアル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 英語版チュートリアル\n",
    "\n",
    "- [本家のチュートリアル](http://tensorflow.org/tutorials)が非常に充実している\n",
    "- 初期リリースということもあり、所々動かないところもあるので注意\n",
    "- TensorFlowをざっくりと理解するには、次に紹介する日本語のチュートリアル＠Qiitaからやり始めることをオススメします"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 日本語版チュートリアル\n",
    "\n",
    "- ミニマルな例を扱っている以下のチュートリアル群がいい感じ\n",
    "    - [TensorFlowのコード分割の考え方](http://qiita.com/sergeant-wizard/items/98ce0993a195475fd7a9)\n",
    "    - [TensorBoardでスカラのグラフを出力する](http://qiita.com/sergeant-wizard/items/af7a3bd90e786ec982d2)\n",
    "    - [TensorBoardでデータフローを可視化する](http://qiita.com/sergeant-wizard/items/c98597b8add04b8eea0b)\n",
    "- 以下の例は上の例をちょこちょこ変更したもの。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# まずtensorflowを読み込む\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 簡単なデータセットを作成\n",
    "\n",
    "# 入力データ\n",
    "x_data = [\n",
    "  [1., 0., 0.],\n",
    "  [0., 1., 0.],\n",
    "  [0., 0., 1.]\n",
    "]\n",
    "\n",
    "# 出力データ\n",
    "y_data = [\n",
    "  [0., 0., 1.],\n",
    "  [1., 0., 0.],\n",
    "  [0., 1., 0.]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 入力データ用のプレースホルダを用意\n",
    "x_pl = tf.placeholder(\"float\", [None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルパラメータ（ウエイトとバイアス）を変数として用意\n",
    "W = tf.Variable(tf.zeros([3, 3]))\n",
    "b = tf.Variable(tf.zeros([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  ソフトマックスを用いた多値分類モデルを作成\n",
    "y_hat = tf.nn.softmax(tf.matmul(x_pl, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 出力データ（ターゲット）用のプレースホルダを用意\n",
    "y_pl = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "# 損失関数を定義\n",
    "cross_entropy = - tf.reduce_sum(y_pl * tf.log(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 損失関数を最適化するための手法を用意。ここでは最急勾配法という最適化手法を使用\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 全ての変数を初期化する手順を用意\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# プレースホルダに入れる実データを設定\n",
    "feed_dict={x_pl: x_data, y_pl: y_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.27587\n",
      "1.85469\n",
      "1.17299\n",
      "0.821553\n",
      "0.619587\n",
      "0.492207\n",
      "0.40589\n",
      "0.3441\n",
      "0.297949\n",
      "0.2623\n"
     ]
    }
   ],
   "source": [
    "# セッションを開始\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # 初期化を実行\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1000):\n",
    "        \n",
    "        # 学習を１ステップ分実行\n",
    "        sess.run(train_step, feed_dict=feed_dict)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            # 100ステップごとにクロスエントロピーを表示する\n",
    "            print sess.run(cross_entropy, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference, Loss, Trainingにコードを分割\n",
    "\n",
    "- モデルが複雑になっても、見通しよくコーディングを進めるため"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [\n",
    "  [1., 0., 0.],\n",
    "  [0., 1., 0.],\n",
    "  [0., 0., 1.]\n",
    "]\n",
    "\n",
    "y_data = [\n",
    "  [0., 0., 1.],\n",
    "  [1., 0., 0.],\n",
    "  [0., 1., 0.]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 推定関数を用意：モデルを定義する\n",
    "def inference_fn(x_pl):\n",
    "    '''\n",
    "    Args:\n",
    "        x_pl: 入力データ用プレースホルダ\n",
    "        \n",
    "    Returns:\n",
    "        モデルによる出力データの予測値\n",
    "    '''\n",
    "    \n",
    "    #  名前空間を設定（TensorBoardが見やすくなる）\n",
    "    #with tf.name_scope('inference_fn') as scope:\n",
    "\n",
    "    # モデルパラメータ（ウエイトとバイアス）を変数として用意\n",
    "    W = tf.Variable(tf.zeros([3, 3]), name='W_var')\n",
    "    b = tf.Variable(tf.zeros([3]), name='b_var')\n",
    "\n",
    "    # ソフトマックスを用いた多値分類モデルを作成\n",
    "    y_hat = tf.nn.softmax(tf.matmul(x_pl, W) + b)\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 誤差関数を用意：\n",
    "def loss_fn(y_hat, y_pl):\n",
    "    '''\n",
    "    Args:\n",
    "        y_hat:  モデルによる出力データの予測値\n",
    "        y_pl: 出力データ用プレースホルダ\n",
    "\n",
    "    Returns:\n",
    "        クロスエントロピー誤差\n",
    "    '''\n",
    "    \n",
    "    #  名前空間を設定（TensorBoardが見やすくなる）\n",
    "    #with tf.name_scope('loss_fn') as scope:\n",
    "\n",
    "    # 損失関数を定義\n",
    "    cross_entropy = - tf.reduce_sum(y_pl * tf.log(y_hat))\n",
    "\n",
    "    # TensorBoard用にcross_entropyの値をxentという名前で保存\n",
    "    tf.scalar_summary(\"xent\", cross_entropy)   # <<<< For TensorBoard\n",
    "    \n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_fn(loss):\n",
    "    \n",
    "    #  名前空間を設定（TensorBoardが見やすくなる）\n",
    "    #with tf.name_scope('training_fn') as scope:\n",
    "    \n",
    "    # 損失関数を最適化するための手法を用意。ここでは最急勾配法という最適化手法を使用\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "    \n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.27587\n",
      "1.85469\n",
      "1.17299\n",
      "0.821553\n",
      "0.619587\n",
      "0.492207\n",
      "0.40589\n",
      "0.3441\n",
      "0.297949\n",
      "0.2623\n"
     ]
    }
   ],
   "source": [
    "# TensorFlowにモデルはデフォルトのグラフに組み込まれると伝える\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    # 入力データ用プレースホルダを用意\n",
    "    x_pl = tf.placeholder(\"float\", [None, 3], name='x_pl')\n",
    "\n",
    "    # 出力データ用プレースホルダを用意\n",
    "    y_pl = tf.placeholder(\"float\", [None, 3], name='y_pl')\n",
    "    \n",
    "    # プレースホルダに入れる実データを設定\n",
    "    feed_dict = {x_pl: x_data, y_pl: x_data}\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        #モデルの予測値\n",
    "        y_hat = inference_fn(x_pl)\n",
    "\n",
    "        # 損失関数\n",
    "        loss = loss_fn(y_hat, y_pl)\n",
    "\n",
    "        # 学習\n",
    "        training_op = training_fn(loss)\n",
    "\n",
    "        # 変数を初期化する用意\n",
    "        init = tf.initialize_all_variables()\n",
    "        # 変数を初期化\n",
    "        sess.run(init)\n",
    "\n",
    "        # dataというディレクトリに結果を保存するための用意\n",
    "        #summary_writer = tf.train.SummaryWriter('logdir') # <<<< For TensorBoard\n",
    "        #\n",
    "        # dataというディレクトリに結果と計算グラフを保存するための用意\n",
    "        summary_writer = tf.train.SummaryWriter('logdir', graph_def=sess.graph_def) # <<<< For TensorBoard\n",
    "        \n",
    "        # サマリをまとめる（下に持ってきたらエラー消えた）\n",
    "        summary_op = tf.merge_all_summaries() # <<<< For TensorBoard\n",
    "        \n",
    "        \n",
    "        for step in range(1000):\n",
    "\n",
    "            # 学習を１ステップ分実行\n",
    "            sess.run(training_op, feed_dict=feed_dict)\n",
    "\n",
    "            if step % 100 == 0:\n",
    "\n",
    "                # 100ステップごとにクロスエントロピーを表示する\n",
    "                print sess.run(loss, feed_dict=feed_dict)\n",
    "\n",
    "                # 結果の保存を実行\n",
    "                summary_str = sess.run(summary_op, feed_dict=feed_dict) # <<<< For TensorBoard\n",
    "                summary_writer.add_summary(summary_str, step) # <<<< For TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir=${PWD}/logdir"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
